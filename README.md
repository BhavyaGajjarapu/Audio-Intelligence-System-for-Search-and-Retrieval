# ğŸ§ Audio Intelligence Pipeline

This project is a modular audio processing and retrieval system designed to handle large sets of audio files. It performs the following:

- Converts audio to machine-readable `.wav` format
- Transcribes speech using OpenAI's Whisper
- Tags environmental and musical sounds using PANNs
- Stores structured metadata (e.g., transcript, tags, duration)
- Supports tag-based and text-based search for retrieval

---

## ğŸš€ Features

- ğŸ“¥ **Audio Ingestion**: Upload and normalize audio files.
- ğŸ§  **Transcription**: High-quality speech-to-text using Whisper.
- ğŸ·ï¸ **Audio Tagging**: Detects over 500+ sound categories using PANNs.
- ğŸ—ƒï¸ **Metadata Storage**: JSON-based and folder-based structured storage.
- ğŸ” **Search Interface**: Search by keywords in transcript or detected tags.

---

## ğŸ“ Project Structure

project_root/

â”œâ”€â”€ uploaded_audios/ # Raw uploaded audio files

â”œâ”€â”€ processed_audios/ # Normalized and converted .wav files

â”œâ”€â”€ transcripts/ # Transcribed text in JSON format

â”œâ”€â”€ metadata/ # Metadata including tags, duration, etc.

â”œâ”€â”€ app.py # Main pipeline execution script

â”œâ”€â”€ requirements.txt # Python dependencies

â””â”€â”€ README.md # Project description and usage


## Install dependencies:

pip install -r requirements.txt


## ğŸ§ª How to Use

Place your audio files in uploaded_audios/.

## Run the pipeline:

python app.py

## Outputs:

Normalized audio â†’ processed_audios/

Transcript â†’ transcripts/

Metadata with tags â†’ metadata/

## ğŸ” Search Example

You can write search utilities to:

Match keywords from the transcript

Match PANN tags such as "speech", "dog barking", "applause", etc.

## ğŸ§  Models Used

Whisper: For speech transcription

PANNs (Cnn14): For audio tagging

## ğŸ“Œ TODO

 Add web interface

 Support session-based refinement search

 Integrate vector-based semantic search
